{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extração das imagens do .rec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import mxnet as mx\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_path = '../data/CASIA/faces_webface_112x112/'\n",
    "output_dir = '../data/CASIA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_mx_rec(df, rec_path, save_path, write_img=True):\n",
    "    if write_img:\n",
    "        if not os.path.isdir(save_path + \"/casia-faces\"):\n",
    "            os.makedirs(save_path + \"/casia-faces\")\n",
    "\n",
    "    imgrec = mx.recordio.MXIndexedRecordIO(\n",
    "        os.path.join(rec_path, 'train.idx'),\n",
    "        os.path.join(rec_path, 'train.rec'), 'r')\n",
    "    img_info = imgrec.read_idx(0)\n",
    "    header, _ = mx.recordio.unpack(img_info)\n",
    "    max_idx = int(header.label[0])\n",
    "\n",
    "    file_path = os.path.join(save_path, \"casia-faces\")\n",
    "\n",
    "    if not os.path.isdir(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    data_list = []  # Lista para armazenar dados antes de escrever no CSV\n",
    "\n",
    "    for idx in tqdm(range(1, max_idx), desc=\"Extracting images\"):\n",
    "        img_info = imgrec.read_idx(idx)\n",
    "        header, img = mx.recordio.unpack_img(img_info)\n",
    "        label = int(header.label)\n",
    "        img_path = f\"{label}_{idx}.jpg\"\n",
    "\n",
    "        if write_img and img_path in df['path'].values:\n",
    "            cv2.imwrite(os.path.join(file_path, img_path), img)\n",
    "\n",
    "        data_list.append([img_path, label])\n",
    "\n",
    "    # Criar DataFrame e salvar em CSV\n",
    "    new_df = pd.DataFrame(data_list, columns=['path', 'id'])\n",
    "    new_df.to_csv(os.path.join(save_path, \"casia.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 490623/490623 [00:41<00:00, 11778.79it/s]\n"
     ]
    }
   ],
   "source": [
    "load_mx_rec(None, rec_path, output_dir, write_img=False) # Não escrever imagens, apenas obter CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Limpeza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens no df: 124,134\n",
      "Total de identidades no df: 784\n"
     ]
    }
   ],
   "source": [
    "# Carregar DataFrame\n",
    "df = pd.read_csv(os.path.join(output_dir, 'casia.csv'))\n",
    "\n",
    "# Filtros e seleção de amostras\n",
    "df_clean = df.groupby('id').filter(lambda x: len(x) >= 100)\n",
    "df_clean = df_clean.groupby('id').filter(lambda x: len(x) <= 300)\n",
    "\n",
    "print(f'Total de imagens no df: {df_clean.shape[0]:,}')\n",
    "print(f\"Total de identidades no df: {df_clean['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300, 158.3341836734694)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['id'].value_counts().min(), df_clean['id'].value_counts().max(), df_clean['id'].value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 490623/490623 [11:16<00:00, 725.26it/s]\n"
     ]
    }
   ],
   "source": [
    "load_mx_rec(df_clean, rec_path, output_dir, write_img=True) # Escreve imagens, somente com amostras selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens na pasta: 124,134\n"
     ]
    }
   ],
   "source": [
    "qtd = len(os.listdir(os.path.join(output_dir, 'casia-faces')))\n",
    "print(f'Total de imagens na pasta: {qtd:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Separar em treino e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = df_clean['id'].value_counts().nsmallest(5).index\n",
    "val_df = df_clean[df_clean['id'].isin(val_ids)].copy()\n",
    "\n",
    "remaining_ids = df_clean[~df_clean['id'].isin(val_ids)]['id'].unique()\n",
    "test_df = df_clean[df_clean['id'].isin(remaining_ids)].copy()\n",
    "test_df = test_df.groupby('id').head(10)\n",
    "\n",
    "train_df = df_clean[~df_clean.index.isin(test_df.index) & ~df_clean.index.isin(val_df.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomear coluna id para id_original\n",
    "train_df.rename(columns={'id': 'id_original'}, inplace=True)\n",
    "val_df.rename(columns={'id': 'id_original'}, inplace=True)\n",
    "test_df.rename(columns={'id': 'id_original'}, inplace=True)\n",
    "\n",
    "# Resetar os índices\n",
    "train_df.loc[:, 'id'], _ = pd.factorize(train_df['id_original'])\n",
    "test_df.loc[:, 'id'], _ = pd.factorize(test_df['id_original'])\n",
    "val_df.loc[:, 'id'], _ = pd.factorize(val_df['id_original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 115,844 imagens | 779 identidades | média de 148.71 imagens por identidade\n",
      "test_df: 7,790 imagens | 779 identidades | média de 10.00 imagens por identidade\n",
      "val_df: 500 imagens | 5 identidades | média de 100.00 imagens por identidade\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_df: {train_df.shape[0]:,} imagens | {train_df['id'].nunique()} identidades | média de {train_df['id'].value_counts().mean():.2f} imagens por identidade\")\n",
    "print(f\"test_df: {test_df.shape[0]:,} imagens | {test_df['id'].nunique()} identidades | média de {test_df['id'].value_counts().mean():.2f} imagens por identidade\")\n",
    "print(f\"val_df: {val_df.shape[0]:,} imagens | {val_df['id'].nunique()} identidades | média de {val_df['id'].value_counts().mean():.2f} imagens por identidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(output_dir, 'train.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(output_dir, 'test.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, 'val.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum erro encontrado\n"
     ]
    }
   ],
   "source": [
    "# Verificar a mesma pessoa em diferentes datasets (treino e teste)\n",
    "erro = False\n",
    "for i in range(train_df['id'].nunique()):\n",
    "    if train_df[train_df['id'] == i].iloc[0]['id_original'] != test_df[test_df['id'] == i].iloc[0]['id_original']:\n",
    "        print(f\"Erro: {train_df[train_df['id'] == i].iloc[0]['id_original']} != {test_df[test_df['id'] == i].iloc[0]['id_original']}\")\n",
    "        erro = True\n",
    "\n",
    "if not erro:\n",
    "    print(\"Nenhum erro encontrado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
